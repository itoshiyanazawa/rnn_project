{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itoshiyanazawa/rnn_project/blob/main/test_Itoshi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "jdpJpXwdTlJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visualkeras"
      ],
      "metadata": {
        "id": "2NhxGISAy4zh",
        "outputId": "759919ea-c144-409b-d06e-750b44e04a64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from visualkeras) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from visualkeras) (2.0.2)\n",
            "Collecting aggdraw>=1.3.11 (from visualkeras)\n",
            "  Downloading aggdraw-1.3.19-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (655 bytes)\n",
            "Downloading visualkeras-0.1.4-py3-none-any.whl (17 kB)\n",
            "Downloading aggdraw-1.3.19-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (997 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m997.4/997.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.19 visualkeras-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import visualkeras"
      ],
      "metadata": {
        "id": "JpVe6Z9ETs-6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish GPU runtime for faster development\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "eWZVYkE2sq0X",
        "outputId": "f95c2e8f-daa2-4e83-b464-a36f4a98ea81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1"
      ],
      "metadata": {
        "id": "0agUriRGTlkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Collect the text dataset:\n",
        "  *   Download the text dataset from a reputable source or use a pre-existing one.\n",
        "\n",
        "2. Clean the text data:\n",
        "  *   Remove unwanted characters, punctuation, and formatting.\n",
        "  *  Convert all text to lowercase to reduce complexity.\n",
        "\n",
        "3. Tokenize the text:\n",
        "  *   Split the text into individual characters.\n",
        "  *   Create a vocabulary of unique tokens and map each token to an integer.\n",
        "\n",
        "4. Create input sequences:\n",
        "  *   Generate input sequences and corresponding targets for training.\n",
        "\n"
      ],
      "metadata": {
        "id": "326JLY1eUDEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collecting the Movie Dialogues dataset from the Cornell University Website"
      ],
      "metadata": {
        "id": "dinGGf8mVE0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\"\n",
        "file_name = \"cornell_movie_dialogs_corpus.zip\"\n",
        "\n",
        "# Download the dataset\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "# Extract the dataset\n",
        "with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"cornell_data\")\n",
        "\n",
        "print(\"‚úÖ Dataset downloaded and extracted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVyLIsEVTvSa",
        "outputId": "003013c7-614a-40b5-87b3-b3b8f3879bf4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset downloaded and extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the Text Data"
      ],
      "metadata": {
        "id": "fpUheOSSVBGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dialogue lines\n",
        "with open(\"cornell_data/cornell movie-dialogs corpus/movie_lines.txt\", encoding='iso-8859-1') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Extract the actual text (5th field) from each line\n",
        "dialogues = []\n",
        "for line in lines:\n",
        "    parts = line.split(\" +++$+++ \")\n",
        "    if len(parts) == 5:\n",
        "        dialogues.append(parts[-1].strip())\n",
        "\n",
        "# Clean the text\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # lowercase\n",
        "    text = re.sub(r\"[^a-zA-Z0-9.,!?'\\n ]+\", ' ', text)  # remove special chars\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # normalize spacing\n",
        "    return text\n",
        "\n",
        "cleaned_dialogues = [clean_text(line) for line in dialogues]\n",
        "\n",
        "# Combine into one long string\n",
        "full_text = ' '.join(cleaned_dialogues)\n",
        "\n",
        "print(\"üßπ Cleaned text preview:\\n\", full_text[:500])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW4UFF4KU-Wi",
        "outputId": "b00ac1e2-1a22-4281-8ea5-e3eb6166b0db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Cleaned text preview:\n",
            " they do not! they do to! i hope so. she okay? let's go. wow okay you're gonna need to learn how to lie. no i'm kidding. you know how sometimes you just become this persona ? and you don't know how to quit? like my fear of wearing pastels? the real you . what good stuff? i figured you'd get to the good stuff eventually. thank god! if i had to hear one more story about your coiffure... me. this endless ...blonde babble. i'm like, boring myself. what crap? do you listen to this crap? no... then gui\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the text"
      ],
      "metadata": {
        "id": "EDhAGZojVq6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Character-level tokenization\n",
        "chars = sorted(set(full_text))  # unique characters\n",
        "char2idx = {ch: idx for idx, ch in enumerate(chars)}  # map char to index\n",
        "idx2char = {idx: ch for ch, idx in char2idx.items()}  # map index to char\n",
        "\n",
        "# Convert all text to a sequence of integers\n",
        "text_as_int = [char2idx[c] for c in full_text]\n",
        "\n",
        "print(\"üß† Total characters:\", len(full_text))\n",
        "print(\"üî§ Vocabulary size:\", len(chars))\n",
        "print(\"Sample encoding:\", text_as_int[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqrcrOjUVtr_",
        "outputId": "bb1115e1-17a4-4463-bb51-6b9c43f16104"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Total characters: 16940151\n",
            "üî§ Vocabulary size: 42\n",
            "Sample encoding: [35, 23, 20, 40, 0, 19, 30, 0, 29, 30, 35, 1, 0, 35, 23, 20, 40, 0, 19, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate input sequences and corresponding targets for training"
      ],
      "metadata": {
        "id": "AV8TXH4NV-GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define sequence length\n",
        "seq_length = 100\n",
        "sequences = []\n",
        "targets = []\n",
        "\n",
        "# Create input and output sequences\n",
        "for i in range(0, len(text_as_int) - seq_length):\n",
        "    sequences.append(text_as_int[i:i + seq_length])\n",
        "    targets.append(text_as_int[i + seq_length])\n",
        "\n",
        "print(\"‚úÖ Total sequences created:\", len(sequences))\n",
        "print(\"Sample input:\", sequences[0])\n",
        "print(\"Sample target:\", targets[0])"
      ],
      "metadata": {
        "id": "7OndtXT6V_Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Efficient data prep\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set sequence length\n",
        "seq_length = 100\n",
        "\n",
        "# Create tf.data.Dataset from integer-encoded text\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "# Create sequences by windowing\n",
        "sequences = char_dataset.window(seq_length+1, shift=1, drop_remainder=True)\n",
        "sequences = sequences.flat_map(lambda window: window.batch(seq_length+1))\n",
        "\n",
        "# Map to (input, target)\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[-1]  # predict ONLY the next character\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "# Batch the sequences\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "n9loaer1x0M3",
        "outputId": "3a95261d-c481-414d-97f6-bdc097bce58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(64, None), dtype=tf.int32, name=None), TensorSpec(shape=(64,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2"
      ],
      "metadata": {
        "id": "z25LiasFTvqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define the RNN architecture (e.g. using Tensorflow or PyTorch).\n",
        "2. Explain the type of layers you are including and why (layers such as Embedding, LSTM, and Linear)\n",
        "3. Visualize your RNN architecture\n",
        "4. Compile the model with appropriate loss function and optimizer. Explain your choice of loos function and optimizer.\n",
        "5. Prepare data for training by converting sequences and targets into batches.\n",
        "6. Train the model on the training data and validate it on the validation set.\n",
        "7. Visualize the training process using both training and validation results.\n"
      ],
      "metadata": {
        "id": "xuHtPOF2i57S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the RNN Architecture"
      ],
      "metadata": {
        "id": "3j4wq9cZjnkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(char2idx)\n",
        "sequence_length = 100\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=64, input_length=sequence_length),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "model.build(input_shape=(None, sequence_length))"
      ],
      "metadata": {
        "id": "RSGRDzyaTyoT",
        "outputId": "5d2907d6-6677-401e-a278-ae15751010ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Layer Breakdown**:\n",
        "- `Embedding`: Converts integer indices into dense 64-dimensional vectors. This helps the model learn semantic relationships between characters.\n",
        "- `LSTM`: Long Short-Term Memory layer with 128 units, captures temporal dependencies and handles vanishing gradient issues better than simple RNNs.\n",
        "- `Dense`: Fully connected output layer with `softmax` activation, outputs probabilities across the vocabulary to predict the next character.\n"
      ],
      "metadata": {
        "id": "YLVpdZWAmNlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the Model"
      ],
      "metadata": {
        "id": "ZObyTrUCnYx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "IVXDHhpdmVSD",
        "outputId": "7f9209b9-2960-487e-d954-10341ae7be10"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        ‚îÇ         \u001b[38;5;34m2,688\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ        \u001b[38;5;34m98,816\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             ‚îÇ         \u001b[38;5;34m5,418\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,418</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m106,922\u001b[0m (417.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,922</span> (417.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m106,922\u001b[0m (417.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,922</span> (417.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualkeras.layered_view(model, legend=True)"
      ],
      "metadata": {
        "id": "fwqe1Cy3zEre",
        "outputId": "69f27374-ca48-4505-b862-9ce91f2a49be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/visualkeras/layered.py:86: UserWarning: The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\n",
            "  warnings.warn(\"The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=174x456>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAAHICAYAAADX1tEdAAAyKUlEQVR4Ae2dB3wU1fbHT3ohEBJCJ3QFDb33DiKColQVxOezY+9PH4r6sICPJ/Zn+wv4VEBEFOmdAJHeIj1AICGEhIQkpCf875kwsFnu7s5O2WlnPh/d3Tu3/s43lzszZ871u8wOoIMU8EIBRObxh+6Ghb8shpioMC9K8rOWl1+G81n5UFxyGU6dToPo6Gh+RofUQIfv9JUU8KgAQvvC03+HhPjVsOunERBdLcRjGXcZysvLYfhTq+FMWi6EhoVKghbrI3DdqUrnKikgQrt25W/w+0cDVIM2M7sIalQPAf9A6bO3f6We0Q9SwIUCWkL70UsdITe/FEJDgly0fn0ygXu9JpTipICW0P7yQW/YnpgJXVvVAD8/P6eWXf8kcF1rQ2eYAlpDG1UtGFYmpEGPtjFe6U3geiWXvTL7AtpLBaXw54FM6HxzDa/EJXC9kss+mX0BLaoZv+c8tLsxCiLCvbtPQODah0XJI/UVtNih1X+mweBudST3TcxI4IpK0KeggC+hxbZWIbhdCVzCT4ECvoQWu/lXUg4EBfpD89gIr3tNM67XklmzgK+hRRXF2dab22Ci+gSuqISNP/WAFuVemXBW1voWyxK4qIKND72gzbxYBIdP5kKPNt7dvxVNReCKStjwUy9oUeq1289Br3YxEBIcIEt5AleWbOYvpCe0qF7FbbC6soUkcGVLZ96CekNbWlYO67anw6AutWWLSODKls6cBfWGFlXbnngBYuuEQ50Y6W6MzmoTuM6KWPi3EaBFefE22BAZT8scTUPgOqph4e9GgRYlXsW8wQbJeFrmaB4C11ENi343ErTJaZcA33ho3yJKkdoEriL5jF/YSNCiWng3YQC7KPP3l+40zlOZwOWpYpE0o0GLsqLTuNL1LdZD4KIKFjyMCK3oNN6vo/zbYKKpCFxRCQt9GhFalFd0Gq8WIf2lSFdmIXBdKWPSdKNCi3LKdRrnmYLA5ali0jQjQ4t9E90Y1ZCXwFVDRQPUYWRoUR4lTuM8eQlcniomSzM6tCin+LRMjtM4zxwELk8VE6WZAVqUE53GlT4tczQLgeuohsm+mwVapU7jPLMQuDxVTJBmFmhRSqVO4zxzELg8VQyeZiZoUUqlTuM8cxC4PFUMnGY2aNVwGueZg8DlqWLQNLNBizKq4TTOMweBy1PFgGlmhBZlFG+DqS0pgau2ohrUZ1ZoUQo1nMZ5khK4PFUMlGZmaNVyGueZg8DlqWKQNDNDixLi3YSBXZU7jfPMQeDyVDFAmtmhRQnRaVxOJEYp8hO4UlTycR4rQKum0zhPfgKXp4qOaVaAFuVT02mcZw4Cl6eKTmlWgRblU9NpnGcOApenig5pVoIWx6Km0zjPHAQuTxUfp1kJWpRObadxnjkIXJ4qPkyzGrQonfi0TC2ncZ45CFyeKj5KsyK0KJ3aTuM8cxC4PFV8kGZVaLVwGueZg8DlqaJxmlWhRdkEp/H2NWVHGpcqPYErVSmV8lkZWpRIuA2mMBKjFKkJXCkqqZTH6tBq5TTOk5/A5amiQZrVoUXJtHIa55mDwOWponKaHaBFycTbYCrLx62OwOXKol6iXaBFxbRyGudZg8DlqaJSmp2g1dJpnGcOApenigppdoIW5dLSaZxnDgKXp4rCNLtBi3Jp7VTjbBIC11kRhb/tCC06jSfszwQ1Io1LlZ/AlaqUhHx2hBZlQadx3EVHjUjjEmQWshC4UpXykM+u0KIsuL5VMxKjB6mF0wSuFJU85LEztDh2X69v0RwErgcoPZ22M7SojS+cxnk2IHB5qkhMszu0KJP4tExLp3GeOQhcnioS0gjaCpF84TTOMweBy1PFQxpBWyGQr5zGeeYgcHmquEkjaK+J4yun8WstXvtG4F7TwuM3grayRL5yGq/casUvApenCieNoK0sii+dxiu3XPGLwOWp4pRG0DoJwn760mn8+tbpPi5Pk0ppBG0lOa7+EG+DXU3w8Reacd0ITtC6FseXTuO8XhC4PFVYGkHrQhiW7GuncV5PCFyOKgQtRxSHJF87jTs0ffUrgXtVioovBK2TIJyfejjVOHeDwHVQhKB1EMPFVz2cxnldIXCvqELQ8vC4Pk0Pp/Hre0G3wwRNCFoeGvw0PZzGeT2x/YxL0PKw4KehVkZY32LvbA0uQcsH1FWqXk7jvP7YFlyCloeD+zTxaZmvncZ5vbIluAQtDwXPaXo5jfN6ZjtwCVoeBp7T9HQa5/XOVuAStDwEpKXp6TTO66FtwCVoeeaXnqan0zivl7YAl6DlmV56mt5O47yeWh5cgpZndu/S0Gm8Yd1wqBMT5l1BDXNbGlyCVh1yjPLQwXE0lgWXoHU0s7LvejuN83pvSXAJWp6p5aUZwWmc13PLgUvQ8swsP80ITuO83lsKXIKWZ2JlaUZc3+KILAMuQasMUF5poziN8/pmCXAJWp5placZxWmcNxLTg0vQ8syqTppRnMZ5ozE1uAQtz6TqpKG2Rl3f4ghNCy5Bqw6grmpBp/HgIH9oHhvhKouu6aYEl6DVnhlxtjWC0zhvtKYDl6DlmVH9NATX1zvpeDMKU4FL0HpjWvl50Wn80Ikc6NEmRn4lGpc0DbgErcYkOFRvNKdxh65d/WoKcAnaq/byyRejOY3zBm14cAlantm0SzOi0zhvtIYGl6DlmUzbNCM6jfNGbFhwCVqeubRPE2+Dad+SshYMCS5Bq8yoSkob0WmcNx7DgUvQ8szkmzTBaZzdCmvfIso3DSpoxVDgErQKLKlCUcFpvEtt8Pf3U6E2baswDLgErbaGllK7Wda3OBZDgEvQSsFK2zxGdhrnjVx3cAlanll8n2Zkp3GeGrqCS9DyTKJPmpGdxnmK6AYuQcszhz5paAszrW9RJV3AJWj1AdRVq0Z3Guf12+fgErQ8M+ibJs62RnUa56njU3AJWp4J9E9DcI3sNM5TyGfgErQ8+fVPM4PTOE8ln4BL0PKkN0aaGZzGeUppDi5By5PdOGlmcBrnqaUpuAQtT3LjpJnFaZynmGbgErQ8uY2VZhancZ5qmoBL0PKkNl6aeBvMeD3z3CPVwSVoPYtulBxmcRrn6aUquAQtT2JjppnJaZynoGrgErQ8eY2bZiancZ6KqoBL0PKkNXaamde3qKxicAlaYwPK653ZnMZ5Y1AELkHLk9T4aWZzGucpKhtcgpYnpznSzOY0zlNVFrgELU9Kc6Sh7cy+vkWlvQaXoDUHoK56aUancd5YvAKXoOVJaK40cbY1k9M4T2HJ4BK0PPnMl4bgms1pnKeyJHAJWp505kszq9M4T+lAXqJjGkI7clhv2LZjF/j7+UG3iUsdT8v6Xl5eDuhSt/aLARBVLVhWHVTIewXM6jTOG6lHcEtKSqBJ0yYQG5kFj4+L49XhddqH3++DJRuT4Z7XtsDXU7pC0wbG3JLI64EZvIBZncZ5snoENzg4GKpHVgcoD4Obm6kTxa9erQho3zIa+nWsCbc9vQGmTW4Ddw2I5fWP0lRSQHQaf/OR1irVqG81kta4WnQRr2r/dntTWPB+T5g++yA8N3MXFBSVadEU1ckUMLPTOM+AuoErdqZV8+qw+vP+kF9QBkMnr4OjybniKfpUUQHxNpiKVepale7g4ugjwoPg81c7wUN3NYfbn90I81cm6yqKFRu3wmNeR7sYAlzsEC4dJgxrDAtn9IJZPx6Gp2bsBPRiokO5Aug0npFtjkjjUkdrGHDFDt/cNBJWftYfyssvw9An1sOhkzniKfqUqYDZncZ5wzYcuNjJKmGB8MnLnWDy2Bvgzuc3wf+WnQS8n0yHPAWstr5FFQwJrmie8bc0gl9n9ob/LjwGk9/bAXn5JeIp+pSoAC63/jyQyW491pZYwhzZDA0uStiiUTVY/kk/CAkOgMGPr4PE4xfNoaxBeolO4+1ujIJqEUEG6ZE63TA8uDjM8NBA+M/zHeD5iS1h9EvxMHvJCVo6SLS/1e4miMM2BbhiZ0cPbAi/f9gH/u+3JHhk2nbIvURLB1Eb3ideF1hxfYtjNRW42OHmsVVh2cf9IJL90zfwsbWw72g2JtPBUcAqTuOcoZkPXBxEWEgAzHimPbz6QByMf2UzfPPrcVo6cKwrzrZmdxrnDM2c4IoDGdmvAfzxUV/4ccUpeODNP+FiXrF4ij6ZAgiuFZzGecY03VLBeRBN6kfAH7P6Qp0aYTDo0XWw69AF5yy2/G0lp3GeAU0PLg4Kb5W9+2RbeOPhVjDhta3wxc9Hbb90sJLTuGXBFQc2vE99WMbu+S5adwYmvZ4AWTn2XTpYyWlctK/jpyVmXMcBNapbhd0y6wuN61WBQeyuw/a/Mh1P2+K76DQ+iO2EbtXDcuCioYKD/OGtx9qwNyvaCjPvp/OOCE47VjWi87is5jTuPD78bUlwxYEO7VEXVnzaH/7YnAoT/rkV8ILFDod4G8zKY7U0uGi42NrhsHhmH2jZpBoMfHQtJOzPsLI9hbFZ9TGvo+EsDy4ONijQH15/qBV8wB5a/P2tP+HDHw5bdulgRadxR2DF77YAVxws3oxf9dkAWLMtDcb/YzOczyoUT1nm04pO4zzj2ApcFKBezTBY9O/e0K5FFLvrsA42M7c/Kx12WN+ivWwHLg46MMBf8HP48IUO8Og722HGnINQVmb+Nyys6jSONnM+bAmuKEL/TrXZq/EDYMveDBj7SjykXzD30sGqTuOivRw/bQ0uClG7Rij8PL0XdG0VI9x12LAz3VEfU323w90E0SC2BxeFCAjwg5cm3QSf/aMTPDl9B7z7baIQlE8UyQyfotP4kG51zNBdxX0kcB0k7N2+FqxmESR3HcqCUS/Gw9mMAoezxv4qOo03s0kAQQLXicdaUaHw07s92VuxtYSXM9HLygyHeDfBik7jPP0JXI4quHR49t6W8NU/uwjB+N7+6gCUlJZzchonycpO4zyVCVyeKlfSureJEe46JCZdhJEsMElKer6b3PqdsrrTOE9ZApenikNaTPUQ+GFaDxjava6wdFix9azDWWN8tbrTOE9lj4GdeYXslubv7wdPjr8RurauAY+y1+Lxvu9rf48T3CeNoIXVncZ5GtOMy1PFRVqXuBrsrkN/SErJY+FQNwA6tOh92MFpnKcxgctTxU1adLUQmPNWN7iDvWE8dPJ6WMp8ffU87OA0ztOXlgo8VTyk4S2nx0bfADgDPzJtm+Cog26T+NKmrw/xNpiv29W7PZpxFVig403Rwl2HM+kFMJxtwnIiNU9BbfKKCutbmzwtc1SIwHVUQ8b36lWD4bupXWHckEZw25Mb4LcNZ2TUIq+I6DSO0RjtdtBSQQWL49LhwTubQee4aHjw7W0QvyeDvazZGkI1XjrYxWmcZyKacXmqyExry2a+NcxN8gJ7KfPWJ9fD8TPa7iBk1/UtmofAlQmpq2IYQPmrKV1g0vAmbN27ERauOe0qq6J0OzmN84QicHmqKEzDpcP9Iyo2H8S3K7TYfNBOTuM8cxC4PFVUShM3HyworNh88MipHJVqBrCT0zhPNAKXp4qKabj5IDqo4+aDdzy3SZXNB+3mNM4zB4HLU0XlNFw6qLn5oNpO4/iHoPWFJE9SJe3S7TCeohqliZsPvvLxHriF7VuMF3E3NYn0qjU09szPD0Npth/0GrfWq7K8zFjf5SI/SCnKg9h64WyHT14uEMK2phaFCVfz6HSk9MB288sCoFb1INj2cUevqyNwvZZMWQHcfPDjlzrBvJWn4K4X4uGfD8bBPUMbCVvCeqoZjT11xl+QdLQAvrlxCAT5K/sHE3fvfP7IBth3KRPG92wEj/+9ObcL2O6bP6bCsQP5EDDyMfaSnjJsLpeXQ+ni/wKcS4IuPdvK8rJT1gPuMClRigL4pA2DkjzEHlhgUJLpT7cTNuN2VVaEdtOWDPip1TCICgp1lVVSejmD5+79S6GovAwm1LoRakYHCHvKORfGdh/5+DisSyyAwElTwC8swjmLV7+x3dK50wBKWezi9gMhJEheBHllf7JedZkyOysgdfNBR2h/jFMP2sySQphz40CIDAh27prwW4T2t205EHDfP1WBtgShvZQDMO5FtgtNFW67UhIJXCkqaZjH0+aDWkNbPTCEOzrtoVU2cxO4XLP5PhE3H1wyqw9893sSPPyvis0HCVrXdqA1rmttfH6mWYOqsPSjfvD65/ug/yOrIa5OtLCB9JQm3WDbxTRF/WFLVfhP8k52JV8K7zbuCudLCoT/sFJcMgTllsGhkzlQWFwK//rxDGBEn8DBE6D81EGF7V6GsvjfAEpYUG1heaBsphU7Q+CKShjkU9x88CG2b9vSTWehUXgkfJqyV3Hv8CIsoygf6gSHwz9PbatUX2ZpIfjtBPjzZAacv1gCmTkl4B9dB8o3M+CUHuwizK+0BC7f/yZb06oDLXaJwFVqGI3KP89CQh3aXQBbe0xUpYVDeZkwasciWBE34rr6PkrdB8GdyuCVZ1oKs+6A1w5BxHOfXZdPTkJZWjLkfvOGqtBiP2iNK8caVEZ3BQhc3U1AHZCjAIErRzUqo7sCBK7uJqAOyFGAwJWjGpXRXQECV3cTUAfkKEDgylGNyuiuAIGruwmoA3IUIHDlqEZldFeAwNXdBNQBOQoQuHJUozK6K0C+CrqbQN8OoOvkyaJc2LL+LCzZdxqKisugvCxK3U7xNu1Ed7ULaRAYyzvpuXkC17NGls2B0E5P2Q3H/LNg7rRugFF4TrCg1Q98ckbdMTu/W4nQblgANXJOwOvjushqi8CVJZv5C4nQJkAaLP6qN0RVq3h9B5kCZ9DUHO4VaGul7Yb4T7pcbdfbJmiN661iFsjvCO0vX/SUDY/XUjhCO6uzonYJXK/VN3cBK0CLFiBwzc2h173HNS0uD3w602Iv2ZpWWB4onGnFAdMaV1TCYJ84Mxaw98PwzQU1jqT8bCi+XAbrS1Ng1uvt4dyFQuE/57qTWEzf8uISwDcX1DjKMtm+cCyWgprQYr8IXDWso0Ed+45mQ6lfOdx/aInLsEjOzWJkmtz8UsD31oKDKv9jWsbOFV8uB79wFr3mP7udi179XVxSDsF+IRDw09uS271amPPFr+wyBIUEQbxKM63YBIErKmGwz6Wbz8Lzj9wAE29r4lXPjibnsp3fN8FLD7eGUQNjr5bFbVP9WWAw8e7B1RMaf9Gq3cp/lhoPgqqXpsDZDPaSJNu98q4B18CTVhLghoZVYf77veCN/+6vtJFKjcgQn0OLfdaqXQJXKhE+zPe/ZSdhZP8GgAHy5BwtG1eDee/2hH98slf3DQTl9F9KGQJXiko+zINbnH6/9KSwh4SSZuOaRQqbZ7/A1rOrEpQFE1HSD63KErhaKSuz3jXbzkG9mDBA8JQeuAvQ3Le7w9MzdsK6HeeUVmeo8gSuocwBMPv3E3Af27FHrQN3v/zuzW4w+d0dsGl3ulrV6l4Pgau7Ca514PS5fNh16ALc3rf+tUQVvnVpVQO+fr2LEEwvYX+GCjXqXwWBq78Nrvbg+z9OCLewMPSo2kePtjXhi1c7wwNT/4Ttf6nzUEPtPnpTH4HrjVoa5i0pLYcflp9SdZng3N2+HWvBJ690gklTEmD34Szn06b6TeAaxFwrtpyFpg0iuOHs1ezigM614T8vdIB7X9sC+9nTObMeBK5BLDebLRPu8/Ipmdyu39K9Lsxge06Mf3Uz/JV0UW41upYjcHWVv6JxfOsg8dhFGN67ns96c1vv+vCvx9vAuFc2w2EVd7z01QDUvwrwVc8t1M5c9sBh7JCGEBIc4NNR3dk/FkpKL8PYlzfDLx/0AoyIbpaDZlydLYUvJ/60gl2U+WiZ4DzcsYMbwsssiPToF+PhRGqe82nD/iZwdTbN0s2pcDPbXRIvzPQ67rm1MTx9TwsBXryXbIaDwNXZSvikbNII9Z6UyR3O/SOawqOjm7PdLjdB6vkCudX4rByB6zOpr2/oCLsoOnYmD4b2qHv9SR1SHrqzOfzt9qYCvGnMtdLIB4Gro3Xm/nFS2Mc3KNA4Znh8zA1wN9tbeBRb86ZnFeqojvumjaOY+35a7mxBURksWJ0ME4Y1NtzYnr67BdzRrwGMYfDiGwxGPAhcnazy+4YUaN8yChrWkb+frZZdf/G+ljCEPagY81I8ZOWwDaMNdhC4OhnkuyVJut0CkzJkP/Z+2qsP3Ay9O9Ri93nj4WKeseAlcKVYUeU8iewxa0p6AQzuVkflmtWtDuGd+nAr6BxXA+7+xxbIyy9RtwEFtRG4CsSTW3TOkhNwL7t3GhhgfPkR3mmT2whvZNz96ha4VFAqd9iqljO+cqoOV//K0PCL1p4x5EWZK3UQ3vefagdN60fAxClbIb9Qf3gJXFfW0ih90boz0K11DahXM0yjFrSp1t/fD2Y+1wHqxITCpDcS2C7rZdo0JLFWAleiUGplw2WCEZ6UyRlPQIAffPRiR4iqGiy8SYF+FnodBK4Pld97JAsu5BRBv461fdiquk3huvxT9hZFSLA/e4dtG/MuK1e3AYm1EbgShVIjG862E4Y1AZy5zHzgk77/vtYFWDgyePSd7YCxIHx9ELg+Ujz3Ugn8tjFFeMTroyY1bQaD6n09pYtwl+GJ93ZCGQtu58uDwPWR2j+vOQ192M38WtGhPmpR+2bQ8f3/pnaDjOwieObfO1k0Ud/BS+Bqb1/AWLez8aJMxUAfPui2pCYwpOmct7vB6bR8eOHD3T6Dl8CVZB5lmXYezIKCwjLo1a6msooMWhrjQPxvWg/27lquEGgP/1C1PghcrRVm9c9Gv4ThjQHvhVr1wMiSPzJ48c7JlM/3C//KaDlWAldLdVnd2bnFsJzFTBh/SyONW9K/etwn7ScW3hTDPL39daKm8BK4Gtt7/qpkGNSljhDgWOOmDFF9dfZwYv77PWHt9nMwffZBzfpE4GomLVRclKkcfVHD7qpWdXS1EPh5ei9YsikV/v39IdXqdayIwHVUQ+XvCfszhQ1A0DfBbkdM9RBYOKMXLGS3AT/+6YjqwydwVZf0WoVirFv0rrLjgfesEd65S0/AFz8fVVUCAldVOa9Vhjfl12xPAwy4YeejLouu/suM3vDNr0nw7eLjqklB4KomZeWK5rHoNPjaOV6s2P1oUDscfmYz7yfzjsJcFtxPjYPAVUNFpzrw0ecc9ur5pOFNnc7Y92ejulWEZcMHcw8JIaeUKkHgKlWQU37T7vMQFhoAHW+K4py1b1IT9gYF3m1459tE+HlNsiIhKFqjIvn4heewfw7RL8GuF2V8VSpSxQ0ER7PX3oOZe+TtfRu4y+7yHM24LqWRdyKdbe68cVc6jHbYjlReTdYtpcYGgjTjqswH7uNwe5/6ULVKkMo1W6s6cQNBfHM4iL1VEVsn3KsB0ozrlVzuM6MzNV41q7lPmfsWzX3WcQPBbQcyvRoMgeuVXO4zr995TvBJQIPQIU0BcQPBt78+wAKOSA+yR+BK01dSLqPEupXUWQNl6hwXzV4grQXVqkqPo0bgqmRADIb8J/vnbiSLckiHdAXQ6fzNLw/AyfNBsHHLHskFCVzJUrnPiDue3zmgAaBDNR3SFBCh3ZxYAms27oTo6GhpBVkuAleyVK4z4uvZ/1t20tDRF133Xp8zSqDFHhO4KthtVUIa4PP4m5tGqlCb9atQCi0qROCqwInwBq9O2z2p0H2fVqEGtNhhAleh2U6dvQR72IbOI/rWV1iT9YurBS0qReAq5AUvysYMaggYX4AO1wqoCS22QuC61trjmeKScvhhObsos2CgD4+D9yKD2tBi0wSuFwZwzrp8SyrcEFsV0OOJDr4CWkCLLRG4fL0lpc5ZwpzFDbArpKTO6pBJK2hxKASuTIMmsR0h/zpxEYb1rCezBmsX0xJaVI7AlckPOotjdBqMWEhHZQW0hhZbI3Aray7pF+5/MH9lMkw04K6QkgagYSZfQIvdJ3BlGPEPFqElrnkk4DtUdFxTwFfQYosE7jXdJX/DJ2X30y2wSnr5ElpsmMCtJL/nH4dP5cCJlDxhn1vPue2Rw9fQoqoErpdsibtC4gYedFQE9kN/WjmuiUr0I/W9UA93VMQgbvfSRZmgmh4zrWguAldUQsLnbxtSWJCPaIhlLox2P/SEFrUncL0gEJcJ5Jeg3/LA0VQErqMabr4fOJYNZzMKhOjibrJZ/pTeM60oMIErKuHhE2+B4drW7LtCehim29NGgRY7SeC6NVXFybz8Eli8PgXuvbWxhNzWzGIkaFFhAlcCZ7+sPQPd28YABim242E0aNEGBK4HEtFodn5SZkRoCVwP0OLpPUeyISevBPqySCt2O4wKLdqBZlwPNOItsIm3Nbb0rpA8CYwMLYHLs5hDGs60SzalwPih1t8V0mHYwv5sejzGdeyDp+8047pRCMO99+tYG2pFhbrJZa1TRp9pRbUJXFEJp080YMU+ZY2dzlj3p1mgRQsQuC443P7XBSguLYde7Wq6yGGtZDNBi8oTuC74s9OukGaDlsB1AW1WTjGs2HoWxg2x/q6QZoSWwHUB7ryVp9gbDnUAdwG38mFWaAlcDpVoTGFXSItHXzQztAQuB9wtezMgMMAPurSqwTlrjSSzQ0vgcjjEQB/3sdnWqrtCWgFaAtcJ3PNZhbB2+zkYMzjW6Yw1floFWgLXicefViQLscAiI4Kdzpj/p5WgJXAdeCwvx4sytnm0BaMvWg1aAtcB3A1s4+iq4YHQvoW1doW0IrQErgO46L44aURTS12UWRVaAvcKuGns7d34PedhFNtgzyqHlaElcK9Q+sPyU8JWphHhQZbg1urQErhMgbKyyzD3yr1bK1BrB2gJXKYA3retXSMUWt9Q3fTc2gVaApcpMHtJkiX24LUTtLYH98y5fNieeAHu6GfuizK7QWt7cHHH87sGxEKVsEDUwpSHHaFFQ9n2DYgS9loOgnvf8MamBBY7bVdocey2BXdlQho0qlsFbmoSiTqY7rAztGgs24Jr5li3dofWtuCeTL0E+45mw4g+9WmmNZ0CFR225Yz7/dITMHZwQwg12a6QNNNe+yuzHbjFJeXw44pTQjywazIY/xtBW9lGtgN32eZUaNGoGjSPrVpZCQP/ImivN47twMVYt5NMtCskQXs9tJhiK3CPnc4F3Bny1p71+GoYLJWgdW0QW4E794+TcPctjSA4yPjDJmhdQ4tnjG9B9/2XfLawuAzmr0qGCcOaSC6jV0aC1rPytgH3940p0Ia5LjauV8WzKjrmIGiliW8bcMXoi9Jk0ScXQStdd1uAe/DERUhOuwRDutWRroyPcxK03gluC3DnLDkpbK4XFGjM4RK03kGLuY1pSe/H4bLEpYJS+GXtacPuCknQujSd2xOWB3fx+jPQOS4aGtQOdyuEHicJWvmqWx5cIazS8KbyFdKoJEGrTFhLg7ufuS6mXyiCAZ1rK1NJ5dIErXJBLQ0uzrYThjWGABao2SgHQauOJSwLbl5+CSxen2KoizKCVh1osRbLgrtw7Rno2S5GCPahnlzyayJo5WvHK2lJcBGS2b8nGSbWLUHLQ09ZmiXB3X04C3LzS6FP+1rK1FGhNEGrgoicKiwJLvoloLO4v7++F2UELYc4lZIsB+7FvGL4Iz5V910hCVqVCHVRjeXAXbDqNAzsUhtqRoW6GLL2yQSt9hpbClwEBt8pw33K9DoIWt8obylwtx3IhDK2e06PtjG+Uc+pFYLWSRANf1oK3IrZtrEuG5AQtBpSyqnaMuBmXiwCDGQ3bkgjzjC1TSJotdWXV7tlwJ23Mhlu6V4Xoqr5dldIgpaHlfZplgAX4anYp8y3F2UErfaAumrBEuDiHmUhLFZC55ujXY1T9XSCVnVJvarQEuDiO2W4B6+fn2+elBG0XjGmSWbTg5ueVQjrd56D0QMbaiKQc6UErbMi+vw2Pbg/sV0hh/euD9UitN8VkqDVB1Jeq6YGt5w9bMB4YL6IvkjQ8vDRL83U4G7YmQ6RVYOgXYsoTRUkaDWVV1blpgb3Ox/EuiVoZXGleSHTgns2owC27s0QNtjTSiWCVitllddrWnBxc72R/RtotiskQascLi1rMCW4pWXl8P1S7S7KCFotkVOnblOCu2bbOagXEwZxzdTfFZKgVQcsrWsxJbhaxbolaLXGTb36TQfu6XP5sOvQBbi9r7q7QhK06kHli5pMB+73LKzSqIGxEB4aqJo+BK1qUvqsIlOBW1JaDj+wR7z3qbhPGUHrM9ZUbchU4K7Ychaa1I8QdoZUQwWCVg0V9anDVODOZssEtfwSCFp9gFOrVdOAeyIlDxKPXWSeYMp3hSRo1cJHv3pMA+5c9sBh7JCGEBIcoEgtglaRfIYpbApwi9iukOh3qzTQB0FrGO4Ud8QU4C7dnAo3N42Epg0iZA+YoJUtnSELmgJcIfoie6dM7kHQylXOuOUMD+7R5Fw4diYPhvaoK0tFglaWbIYvZHhwMV7CPUMbgZxdIQlaw/Mnu4OGBregqAwWrE4Wds7xdoQErbeKmSu/ocH9fUMKtG8ZBQ3rVPFKVYLWK7lMmdnQ4OKTMm9vgRG0puTQ604bFtzEpItwhrkwDu5WR/KgCFrJUpk+o2HBxYuye29tDIEB0rpI0JqeRa8GII0Kr6pUnvlSQSksYhvs4XamUg6CVopK1spjSHAXrTsD3VrXgHo1wzyqTdB6lMiSGQwJrtRYtwStJZmUNCjDgbv3SBZgWPx+HWu7HQBB61Yey580HLg4205k2z0FBLiOdUvQWp5LjwM0FLi5l0rgt40pwiNeVz0naF0pY690Q4H785rT0KdDLagVzd8VkqC1F5zuRmsYcBFKd7tCErTuzGi/c4YBd+fBLCgoLIPe7WteZwWC9jpJbJ9gGHBnL0li8RIag79/5Ysygtb2jHIFMAS42bnFsJzFTBh/S+VdIQlars0okSlgCHDnr0qGQV3qQI3IkKtGIWivSkFfOAroDi4CivduHcMqEbQcS1FSJQV0Bzdhf6bQIfRNwIOgFWSg/3lQQHdwxdkWd4UkaD1Yi05fVUBXcDOyi2D1tjQYO7ghQXvVJPRFigK6gjtvxSnhtfNItivkm18egM2JJbBm406Ijo6W0nfKY2MFdANXuCi7siskQWtjAmUOXb2w3l52IJMtE8JCA+B35lSz5a9Smmm91M/u2XWbcZPTLkFMZDBBa3cCZY5fF3Dz8kvg3IVCuJAfRjOtTMPZvZikpUJu3iWY81MiLFh1UhW9UtJzoWZ0FVi/eTddiKmiqP0q8WMXSZftN2wasdkV0GWpYHbRqP/6K0Dg6m8D6oEMBQhcGaJREf0VIHD1twH1QIYCBK4M0aiI/goQuPrbgHogQwECV4ZoVER/BQhc/W1APZChAIErQzQqor8Ckh75qtHNtauXwZjRd8HfRzaXtIPO2u2psPvQBZg4fjh8NXuxGl2gOiykgE/ARWjHjx0N/3unNwux5D4KI2r76by/4NCJi9C9dQzUrVvfQnLTUNRSQPOlggjtnH/1lAztO9/sh++mdoPOcRUvUKo1WKrHOgpoCq4SaHu2uz4Uk3Vkp5EoVUAzcAlapaah8u4U0GSNO2vmNPj4w+nQLDYCPpt/SPjPXSdws5IDx7KE5YGSmTY8PLygS5cuR8S2br/99uznnnuur/jb3Wf16tVzsrOzq7nL4+qcq7JiemJi4rGNGzemPvbYY31c1UHp3imgOrjFxcWwcd1yiK1dBfp2qiepNxt2pELHm2qAEmixoeDg4JL169e3ldSoDzPFxcU1x/982KTlm1IdXAYPtG7dDqBBAUx9rKMkAad+DrAj8ZykvHIy4cx311137duwYUOjF1988UR8fHzAli1bGj755JNJzz777NUZmZ3bkJCQEIXBSWbPnh3FylVleRLT0tLC2R9kwAcffBDAZvS4c+fOnX/ooYdOZGVlhTZr1iyH9akN9stVOp4TZ1/x++TJk3exfkSxWT5s6tSpWXfeeWdXx/KNGzfOXbZs2U0ZGRnRWIaOygpotsat3Iy+vwoLC0MeeeSRqHXr1gU8/vjjvZ966qnq7Lv/jBkzWoo9KyoqCu7UqVPwpk2b2jz88MO5bImRykDez8Ctvnr16vbff/99DEsPwvwvvPDCkXHjxpVg3pEjRwZh/e7SxTbET/ZHEBQTE+PH/pDaLlq0KOzpp5+OdS4/atSowLy8PO82MRYbsMGnJq/uTH31SYCsrV7MuDuFGfe7qV0qST599kEIrdsP3nrvs0rprn44r3HffffdgO7du7fC9Nzc3OAAdoSGhhbl5+cH+bPDcRbEPGz2C2D/YgQziIsaNWqUExQUVMpm1HSxvZSUlOqHDh1qwGbD9GPHjkWHsKOUHZGRkcWXLl0Kj42NPctLx/KObWEf2CxeyNIi8Rwrn3vx4sWq7spjPjquKaD6UuFa1b7/5mqNi+mMWWG3P4SGMXstnumVbrK0cpYnWOw1Y7KEzYyBy5cvb8HKhJazg/3Tvp/laYQzppgP09lre0I0alfpYl7xE/sjQotpbGlyGT+llse8dj8MvVQoKS33mX3YxBm4dOnSndjgggULdvTv3z+pZ8+eSeyf8l2YxtabO9kMXoLfe/TocXzx4sVCOju/UwTXVTqWcTzwj8Txt/hdankxv50/DTvjxu85z+LmnoRffx8l2T44Y/Xr12+vWIAtE7IYbP3E3+4+cSZeuHBhMVv37mOzYdA333zTjK1di9i6NvWLL77YG8iOr776KgbrmDlzZr1JkyZlffLJJ/sYbMVsdi5myaGu0t2163jOsTzre3GVKlXysV7HPPS9QgFDrnER2of+tRPmLVgIAwYOtY2t7r///nh2UVirTZs2N27fvv2v559/vpTd/21jGwG8GKjhZly7Qos2Y3cwajzxxBOFYWFhO9m/HgGfffZZhBe2tFVWQ4FrZ2iRuo4dO97EZlhbASh3sIa5OMvILrTl8kCu4exeTpMZl904h53sMS4+EZNy4CPfjOxi261ppWhDefgKaHJxxm+KUkkB9RQwzFJBvSFRTXZQgMC1g5UtOEYC14JGtcOQCFw7WNmCYyRwLWhUOwyJwLWDlS04RgLXgka1w5AIXDtY2YJjJHAtaFQ7DEmTR7484db+sQxG3zUKJtRuAUF+nv9eNmWdgX15mXDvrSPgmz8W8aq0fNpvy1fBnaNGgV/HgQABnk1VdnwfwNkTMHDkaFi94AdL6+NZDRWGj9COGz0GvmwxAHpU9/zK+tdn9sOR/GzoFFET6jawZ+wwhHb02DEQMPZZ8G98s0crlGxdCnD+DHu7+kZoUM+zxh4rNHgGz1OfwgGI0H5+Qz/J0M5M3gWfNusDHRi4djxEaGHU05KhLd/wM8DIJwDqN7eFZJqCqwTarlVr28IAzoNUBG3Dq2/bO1drud+agUvQes8KQStdM03WuLPemgaz3p8BTYIj4JuzicJ/7rqUX1YCB/MuCMsDJTOtY+wCx/Z27dp16JVXXskvKSnxZ+88ln/77bd1duzYcXrWrFnCi4jstfNWvXr1OoBl2KszBRMnTmw3YsSI3fPnz+8u1jNhwoTN7GXKjgUFBZq8vPj6ezNg2gczWQCGOuCXsAzK2X/ujsslhVB+LrlieaBgphVjUeAr8vi6EIvQc5G9+9bLXdtGOKc6uGzwsH7pCqgfUhV6Rku7sNp8IQXaRsSAEmjdifnAAw/4L1mypG6DBg3qMvgSWCSaU/PmzevOwh4JxRB4x5hjDz74YM7hw4drlLGDxVEIwP2Ojx8/Him+zeuuLTnnULPfVq4B/8iaENislaQqSo+zv7N6zaBcAbTYkGMsChbU5BILFHiEvV28dcyYMVf/aCV1yMeZVAeXCQGt27eD4oxieKV5N0nDee9YAuzOOispr5xM6enpkexV80IsywzTsVatWgc91dOhQ4d09qZtcbdu3Vrt2bPnMHvzNuvgwYMNPZWTcx4169C2DRwOjIawwXdLqqIAfoTi5COS8krNxICtMn369FAWEipw0KBB2by4aVgX/qHzYp99/PHHG9m/ZrVx9n7vvfcude7cuZmrOqT2yVU+1cF11ZCe6e+8887R3r173zhs2LB49k9+BAv20c5Tf2655Rb/FStWZDBwgX2msd+hbJb2VMz059kfaHMWRir7Sty06K5du8YlJyensj/4PPYHLIyP/QtxNfZZUlLSaRbLIgL/9Xr77bfj2L9MISxUVTrTPJMttTD2GrcOpULZAlxcs91xxx3Zv/76KzzzzDPhTOT1LEJiP3fiDRky5KZPP/309BtvvAFr166txoLl3cDyC6GS3JUz+zmMhYYx09gfKwKczsYjBFhhq4jq4tKJRZ3y/9vf/tYOx9q0adNYFvcsF7+zieHgfffdF8S0CpozZ07PK7HQuHVgfiWH5cE9f/585tGjR1NZxJnWTOxew4cPz2zdunUUA9etbtHR0VEsVFLy6dOnUzFjtWrVqrKPHLeFLHBy27ZtR5g+Jbt3727Ii5uGQ3QV++y7777rxV6v3/vhhx8W/vDDD/Hsb+BGV3UolUqz22FKO4blSy5zQ2x5VTVbb/mNHTu2pghgZmbmxYYNG56XUsnQoUOzXnvttRNsvSfMKFLK6J6nrFR2F1i83+yXX3458KWXXgp0FTcNK+fFPmOzbk7fvn33stBRN8+dO7cVi8PW0l0dsjt5paBhZ9yE3DSYl3kcFo/5SPIYce3FbmvtFwsw4S68//77fb/88svt7Co5nEWIScebBOwCAmdPj8dtt91Wj4F7w759+457zGyEDMmHwH/fBrjnnRck9wY1w3hreEHFbhcGMHDz2e+uLLxqKi9umquKWajUauxfs2x2TXCcLSX8pkyZco4tz5p7U4erunnpmrye/vpjT0Hxqm1e31X4tElvoY8I7TPJW2H+Lyx22K1Def22XNoDz74EPyaekX5XYVXFXYXyOyZXaMGgDVzyX/h14QK4bchgy+njPCDDLRXsCK2zUbz+bTNoUR9DgUvQeo0sgA2hNRS4mewRpt2WBzIwrVwkP9dWywPHwWtycYaxw7azx7j4REzKgY98L5QV2WpN66wLaoaPcfGJmJRDeOSbn2ObNa2zJppcnDk3Qr9JAbUVMNQaV+3BUX3WVYDAta5tLT0yAtfS5rXu4Ahc69rW0iMjcC1tXusOjsC1rm0tPTIC19Lmte7gCFzr2tbSIyNwLW1e6w7u/wFJaQHPVDCM4AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model with appropriate loss function and optimizer.\n",
        "**Loss Function**:\n",
        "- We use `sparse_categorical_crossentropy` because the target output is a single integer (not one-hot encoded).\n",
        "\n",
        "**Optimizer**:\n",
        "- `Adam` is used for its adaptive learning rate, helping the model converge faster and more reliably during training.\n"
      ],
      "metadata": {
        "id": "K6cnqCUGnbb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "-rUUOQnrnn4V"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare data for training"
      ],
      "metadata": {
        "id": "xPE4L3xjnxiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sequences and targets to NumPy arrays\n",
        "X = np.array(sequences)\n",
        "y = np.array(targets)\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "print(\"Train set shape:\", X_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFGR6344nyVa",
        "outputId": "012869a4-9583-4f0a-ff86-de69231715e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (15246045, 100)\n",
            "Validation set shape: (1694006, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count total number of batches\n",
        "dataset_size = dataset.cardinality().numpy()\n",
        "\n",
        "# fallback if cardinality is infinite (happens sometimes)\n",
        "if dataset_size == tf.data.INFINITE_CARDINALITY:\n",
        "    dataset_size = 0\n",
        "    for _ in dataset:\n",
        "        dataset_size += 1\n",
        "\n",
        "print(f\"Total dataset size: {dataset_size}\")\n",
        "\n",
        "# Calculate split sizes\n",
        "train_size = int(0.7 * dataset_size)\n",
        "val_size = int(0.1 * dataset_size)\n",
        "test_size = dataset_size - train_size - val_size  # to ensure full coverage\n",
        "\n",
        "# Split datasets\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_test_dataset = dataset.skip(train_size)\n",
        "\n",
        "val_dataset = val_test_dataset.take(val_size)\n",
        "test_dataset = val_test_dataset.skip(val_size)\n",
        "\n",
        "print(f\"Train batches: {train_size}\")\n",
        "print(f\"Validation batches: {val_size}\")\n",
        "print(f\"Test batches: {test_size}\")\n"
      ],
      "metadata": {
        "id": "DmEsTvzd0lFM",
        "outputId": "32231e85-1c1a-4b18-c9b1-feaabb52a40e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size: -2\n",
            "Train batches: -1\n",
            "Validation batches: 0\n",
            "Test batches: -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model"
      ],
      "metadata": {
        "id": "pkZ1pxxVqlmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=128,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "btQOItnDqknN",
        "outputId": "6c5c6117-3901-450c-d9c9-0d2479ca705e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m  2952/119110\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m10:37:03\u001b[0m 329ms/step - accuracy: 0.3258 - loss: 2.3777"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    batch_size=128,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "id": "76lvDJ1O0wRj",
        "outputId": "8f8b79a6-0e18-4873-a5d2-17105fb26306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  38469/Unknown \u001b[1m741s\u001b[0m 19ms/step - accuracy: 0.5369 - loss: 1.5128"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-c2842b7c1522>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Model Accuracy and Loss"
      ],
      "metadata": {
        "id": "tNHP0OzDqpgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Plot\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(\"Model Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Loss Plot\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title(\"Model Loss Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XMwCjBpSqxgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 Summary\n",
        "\n",
        "- The RNN uses an Embedding layer to learn dense vector representations of characters.\n",
        "- An LSTM layer with 128 units captures temporal dependencies in character sequences.\n",
        "- A Dense layer with `softmax` outputs the probability distribution over the vocabulary.\n",
        "\n",
        "Compiled with `sparse_categorical_crossentropy` and `adam`, the model learns to predict the next character in a sequence.\n"
      ],
      "metadata": {
        "id": "cxP3LkvTq5kQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3"
      ],
      "metadata": {
        "id": "z1gcJ_mRTzj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create a function to generate text by sampling from the model's predictions.\n",
        "\n",
        "Qualitative Evaluation:\n",
        "\n",
        "2. Coherence and Grammar: Check if the generated text is grammatically correct and coherent.\n",
        "\n",
        "3. Creativity: Evaluate if the generated text is creative and interesting.\n",
        "\n",
        "4. Contextual Relevance: Assess whether the generated text maintains context and follows logically from the seed text.\n",
        "\n",
        "5. Diversity: Ensure that the model does not repeat itself excessively and generates diverse outputs.\n",
        "\n",
        "Quantitative Evaluation:\n",
        "\n",
        "6. Perplexity: A common metric for evaluating language models. Perplexity measures how well the model predicts the next token in a sequence. Lower perplexity indicates better performance.\n",
        "\n",
        "7. BLEU Score: Used to evaluate the quality of text that has been machine-translated from one language to another. It can be adapted to measure the overlap between generated text and reference text.\n",
        "\n",
        "8. ROUGE Score: Commonly used for evaluating summarization and translation models. It measures the overlap of n-grams between the generated text and a reference text.\n",
        "\n",
        "9. Entropy and Repetition Metrics: Measure the diversity of the generated text. High entropy and low repetition indicate diverse and less repetitive outputs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EKEPJXYFU1qB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJr6ZNvCT1Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4"
      ],
      "metadata": {
        "id": "daklMQk7i2n8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Experiment with different architectures (e.g., adding more layers, or trying other layer types).\n",
        " * Try deeper networks, different activation functions, or different layer configurations.\n",
        " * Example: Adding more LSTM layers or using GRU instead of LSTM.\n",
        "2. Apply regularization techniques (e.g., Use dropout to prevent overfitting).\n",
        "3. Use advanced text preprocessing.\n",
        " * Implement techniques like stemming, lemmatization, or BPE (Byte Pair Encoding) for\n",
        "better tokenization.\n",
        "4. Fine-tune hyperparameters (e.g., learning rate, batch size).\n",
        " * Experiment with different learning rates, batch sizes, and epochs.\n",
        " * Explain your approach for fine-tuning the hyper-parameters."
      ],
      "metadata": {
        "id": "NAmXTKKUVXWc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q58FY70Yi4Wn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}